---
title: "preprocess_for_cross-species"
author: "Beth Moore"
date: "2023-07-07"
output: html_document
---
# Preprocessing for cross species analysis
# to have cross species, we need ortholog genes
# we then need to subset both reference and query by these genes
# reference data will also be subseted by its metadata

# Load libraries, set wd, and source functions
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(Seurat)
library(patchwork)
library(scran)
library(BiocParallel)
library(DropletUtils)
library(cowplot)
library(harmony)
library(SoupX)
library(scDblFinder)
library(reticulate)
library(purrr)
library(jsonlite)
library(rmarkdown)
# #install.packages("Matrix", repos="http://R-Forge.R-project.org")
library(Matrix)
# set up dirs
WD <- "/w5home/bmoore/scRNAseq/GAMM/human_data/cowan_cell_2020/"
GIT_DIR <- "/w5home/bmoore/Gamm_scRNAseq/"
PROJECT_NAMES <- list("F49B7","gammS2")
# use environment
use_condaenv("scRNAseq_best")
# set working directory
setwd(WD)
# create output folder
timestamp <- format(Sys.time(), "%Y%m%d_%H%M%S")
output <- paste0("output_preprocess_test_", timestamp)
dir.create(output, showWarnings = FALSE)
output <- paste0(output, "/")
# copy config and source functions
file.copy(paste0(GIT_DIR,"config.json"), file.path(paste0(output, "config.json")))
config <- fromJSON(file.path(output, "config.json"))

source(paste0(GIT_DIR,"src/sc_pipeline_functions.R"))

```
# Read in data
```{r data}
# refernce data
ref.matrix <- read_aligned_data(
    paste0(WD,"STAR_output/output_F49i-N-B7/Solo.out/GeneFull/"),
    "F49i-N-B7",output
    )

# load gamm pig data sample 2
query.matrix <- read_aligned_data(
    "/w5home/bmoore/scRNAseq/GAMM/STAR_output/output_S2_mm_mt/Solo.out/GeneFull/",
    "gamm.data.S2",output
    )
```

# run soupx
```{r soupx}
all_aligned_data <- list(ref.matrix,query.matrix)
soupX_objs <- purrr::map(all_aligned_data, ~prep_seurat_and_soupX(data.raw = .x$raw, data = .x$filtered, project = .x$project), .names = purrr::map_chr(all_data, 'project'))

# get soup matrices
ref.matrix.soupx<- soupX_objs[[1]]$out
query.matrix.soupx<- soupX_objs[[2]]$out
```
# Create Seurat objects and convert to sce objects for doublet removal
```{r}
project_names <- purrr::map_chr(all_aligned_data, 'project')
feature_set1 <- list(feature1 = 'nCount_RNA', feature2 = 'nFeature_RNA')
filtered_list_of_objs <- purrr::map2(soupX_objs, project_names, ~create_seurat_and_sce(out = .x$out, project = .y, feature_set = feature_set1))
print(project_names)
```
# Doublet removal and lane merging
```{r}
combine_feature_plots(filtered_list_of_objs, feature_set1, file_name_base = "post_soupx_qc")
filtered_sce_list <- list(filtered_list_of_objs[[1]]$sce, filtered_list_of_objs[[2]]$sce)
lane_and_merged_seurat_obj <- run_scDblFinder_and_merge(filtered_sce_list)
print(unique(lane_and_merged_seurat_obj$orig.ident))
```
# get sparse count matrices
```{r}
obj.list <- SplitObject(lane_and_merged_seurat_obj, split.by = "orig.ident")
human_ref<- obj.list[[1]]
pig_query<- obj.list[[2]]
ref.matrix.flt <- human_ref@assays$RNA@data
gam.matrix.flt <- pig_query@assays$RNA@data

rm(ref.matrix.soupx,query.matrix.soupx)
```
# create seurat object
```{r} 
#project_names= PROJECT_NAMES
human_ref.seurat<- CreateSeuratObject(ref.matrix.flt, project = project_names[[1]], assay = "RNA",
                                       min.cells = 3, min.features = 200)
pig_query.seurat<- CreateSeuratObject(gam.matrix.flt, project = project_names[[2]], assay = "RNA",
                                       min.cells = 3, min.features = 200)
```
# Mitochondrial gene filtering
```{r}
human_ref.seurat_mt_filtered <- filter_cells(human_ref.seurat)
pig_query.seurat_mt_filtered <- filter_cells(pig_query.seurat)
```
# read in orthologs and subset
```{r ortho_subset}
objs.list <- ortholog_subset(human_ref.seurat_mt_filtered,pig_query.seurat_mt_filtered,project_names)
ref.seurat <- objs.list[[1]]
query.seurat <- objs.list[[2]]
orthologs <- objs.list[[3]]
print(ref.seurat)
print(query.seurat)
```
# get metadata
```{r metadata}
# "f49b7"
ref.seurat <- get_metadata(ref.seurat, "ref")
print(colnames(ref.seurat@meta.data))
print(table(ref.seurat$orig.ident))
print(table(ref.seurat$EGA))
print(table(ref.seurat$cell_type2))
```

# save seurat object
```{r}
saveRDS(ref.seurat, file = paste0(output,"human_",project_names[[1]],"_ortholog.rds"))
saveRDS(query.seurat, file = paste0(output,"query_",project_names[[2]],"_ortholog.rds"))
rm(human_ref.seurat_mt_filtered,human_ref.seurat,pig_query.seurat_mt_filtered,pig_query.seurat)
```
# Normalization
```{r normalization}
ref.seurat_norm <- normalize_data(ref.seurat)
query.seurat_norm <- normalize_data(query.seurat)
saveRDS(ref.seurat_norm, file = paste0(output,"human_",project_names[[1]],"_norm.rds"))
saveRDS(query.seurat_norm, file = paste0(output,"query_",project_names[[2]],"_norm.rds"))
rm(ref.seurat,query.seurat)
```
## further steps: 
# for scPRED: reference undergoes feature selection, scaling, and dimensional reduction, query does not
#    # if doing a test set for scPred, stop here and load normalized data into scPred. 
#    # Scpred will split the reference into training and testing, then do the rest of the steps.
# for Seurat integration or mapping: query also undergoes feature selection

# Feature selection
```{r feat_select}
#gamm.S2.seurat_norm<-readRDS(file = "output_20230711_155556/GAMM_S2_norm.rds")
#human_D205.seurat_norm<-readRDS(file = "output_20230711_155556/human_D205_norm.rds")
query.seurat_feat_select <- feature_selection(query.seurat_norm)
ref.seurat_feat_select <- feature_selection(ref.seurat_norm)
```
# Scaling data
```{r scale}
query.seurat_scaled <- scale_data(query.seurat_feat_select)
ref.seurat_scaled <- scale_data(ref.seurat_feat_select)
```
# Dimensional reduction
```{r dim_reduct}
query.seurat_dim_reduced <- run_and_visualize_pca(query.seurat_scaled)
ref.seurat_dim_reduced <- run_and_visualize_pca(ref.seurat_scaled)
```
# Run umap
```{r umap}
query.seurat_umap <- run_umap(query.seurat_dim_reduced)
ref.seurat_umap <- run_umap(ref.seurat_dim_reduced)
```
# clustering
```{r cluster}
query.seurat_clustered <- perform_clustering(query.seurat_umap)
ref.seurat_clustered <- perform_clustering(ref.seurat_umap)

```
# save
```{r save}
# save objects
saveRDS(query.seurat_clustered, file = paste0(output, "query",project_names[[2]],"_clustered.rds"))
saveRDS(ref.seurat_clustered, file = paste0(output, "human_",project_names[[1]],"_clustered.rds"))
# save session info
writeLines(capture.output(sessionInfo()), paste0(output,"sessionInfo.txt"))
```